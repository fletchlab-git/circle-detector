{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01619ad5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from decimal import Decimal\n",
    "import statsmodels.api as sa\n",
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cbb0b0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Post-processing histograms output by detect.py: (1) normalize (2) threshold (3) generate means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55556cba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dir_of_images = 'path/to/directory/with/sobel/filtered/histograms'\n",
    "other_dir_of_images = 'likely/more/than/one/path'\n",
    "\n",
    "titration_ls = [dir_of_images, other_dir_of_images]\n",
    "container = []\n",
    "for element in titration_ls:\n",
    "    bead_container = []\n",
    "    for file in Path(element).glob(\"**/*[0-9].csv\"):\n",
    "        csv = pd.read_csv(file,header=None)\n",
    "        trunc = csv[:100] #threshold your histogram appropriately\n",
    "        n_pix = csv.sum(axis = 0) #prep to normalize the histogram\n",
    "        h = trunc / n_pix[0] #sum(h) equals 1\n",
    "        i = np.array(trunc[0].index) #i goes from 0 to 100 (arbitrary threshold)\n",
    "        pre_mu = []\n",
    "        for j in range(len(h)):\n",
    "            elem_pair = h[0][j]*i[j]\n",
    "            pre_mu.append(elem_pair)\n",
    "        mu = np.sum(pre_mu) #mean\n",
    "        bead_container.append(mu) #all of the beads for a specific population\n",
    "    container.append(bead_container) #all of the beads for all populations. each pop an element of list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fb0690",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Plotting 2 conditions (positive and negative). If there is a directory for each condition, this visualization can be expanded. Bar chart works best for two conditions; categorical scatter works best for a titration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d91c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.bar(x='positive condition',height=np.array(container[0]).mean(),yerr = np.array(container[0]).std(), width=0.5, color='tab:orange')\n",
    "plt.bar(x='negative condition',height=np.array(container[1]).mean(),yerr = np.array(container[1]).std(),width=0.5,color='b')\n",
    "plt.ylabel('Mean Pixel Value (Sobel Filtered Bead)')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Determining statistical significance between condition populations:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = {'condition 1': container[0], 'condition 2': container[1]} #create a dictionary to organize the list of lists\n",
    "\n",
    "df = pd.concat([pd.Series(v, name=k) for k, v in d.items()], axis=1) #convert the lists to a df\n",
    "pops = df.stack().reset_index() #stack the conditions to create one big population of conditions\n",
    "\n",
    "stats_df = pd.DataFrame() #this is the object we will run statistical tests on\n",
    "stats_df['condition'] = pops['level_1']\n",
    "stats_df['means'] = pops[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Are your conditions different? Try the non-parametric one-way ANOVA (aka Kruskal-Wallis test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ls = []\n",
    "for element in container:\n",
    "    ls.append(np.asarray(element)) #elements need to be numpy arrays for this test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "H, p = ss.kruskal(*ls) #p will suggest to us: \"yes, these conditions are meaningfully distinct\" or \"no they are not\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p #check p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If conditions are different, it's good to follow up with a post-hoc test. Here we choose Conover's test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sp.posthoc_conover(stats_df, val_col='means', group_col='dilution', p_adjust = 'holm') #take a look at pairwise comparisons!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}